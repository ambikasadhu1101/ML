{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Chance of admit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Admission_predict.csv\")\n",
    "df2=pd.read_csv(\"Admission_Predict_Ver1.1.csv\")\n",
    "dataset=pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.00000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>228.277778</td>\n",
       "      <td>316.621111</td>\n",
       "      <td>107.288889</td>\n",
       "      <td>3.102222</td>\n",
       "      <td>3.385556</td>\n",
       "      <td>3.47000</td>\n",
       "      <td>8.586433</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.722900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>134.674991</td>\n",
       "      <td>11.369700</td>\n",
       "      <td>6.073968</td>\n",
       "      <td>1.143048</td>\n",
       "      <td>0.997612</td>\n",
       "      <td>0.91319</td>\n",
       "      <td>0.600822</td>\n",
       "      <td>0.497303</td>\n",
       "      <td>0.141722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>113.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>225.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>8.570000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>338.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.052500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
       "count  900.000000  900.000000   900.000000         900.000000  900.000000   \n",
       "mean   228.277778  316.621111   107.288889           3.102222    3.385556   \n",
       "std    134.674991   11.369700     6.073968           1.143048    0.997612   \n",
       "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
       "25%    113.000000  308.000000   103.000000           2.000000    2.500000   \n",
       "50%    225.500000  317.000000   107.000000           3.000000    3.500000   \n",
       "75%    338.000000  325.000000   112.000000           4.000000    4.000000   \n",
       "max    500.000000  340.000000   120.000000           5.000000    5.000000   \n",
       "\n",
       "            LOR         CGPA    Research  Chance of Admit   \n",
       "count  900.00000  900.000000  900.000000        900.000000  \n",
       "mean     3.47000    8.586433    0.554444          0.722900  \n",
       "std      0.91319    0.600822    0.497303          0.141722  \n",
       "min      1.00000    6.800000    0.000000          0.340000  \n",
       "25%      3.00000    8.140000    0.000000          0.640000  \n",
       "50%      3.50000    8.570000    1.000000          0.730000  \n",
       "75%      4.00000    9.052500    1.000000          0.822500  \n",
       "max      5.00000    9.920000    1.000000          0.970000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.drop([\"Serial No.\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRE Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831137</td>\n",
       "      <td>0.650135</td>\n",
       "      <td>0.613269</td>\n",
       "      <td>0.538649</td>\n",
       "      <td>0.829021</td>\n",
       "      <td>0.570726</td>\n",
       "      <td>0.806873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL Score</th>\n",
       "      <td>0.831137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669767</td>\n",
       "      <td>0.650534</td>\n",
       "      <td>0.552455</td>\n",
       "      <td>0.818476</td>\n",
       "      <td>0.476830</td>\n",
       "      <td>0.791934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <td>0.650135</td>\n",
       "      <td>0.669767</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730656</td>\n",
       "      <td>0.631142</td>\n",
       "      <td>0.723023</td>\n",
       "      <td>0.436357</td>\n",
       "      <td>0.699380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>0.613269</td>\n",
       "      <td>0.650534</td>\n",
       "      <td>0.730656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692200</td>\n",
       "      <td>0.714796</td>\n",
       "      <td>0.424001</td>\n",
       "      <td>0.680378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>0.538649</td>\n",
       "      <td>0.552455</td>\n",
       "      <td>0.631142</td>\n",
       "      <td>0.692200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.651118</td>\n",
       "      <td>0.383256</td>\n",
       "      <td>0.655735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>0.829021</td>\n",
       "      <td>0.818476</td>\n",
       "      <td>0.723023</td>\n",
       "      <td>0.714796</td>\n",
       "      <td>0.651118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509915</td>\n",
       "      <td>0.878284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>0.570726</td>\n",
       "      <td>0.476830</td>\n",
       "      <td>0.436357</td>\n",
       "      <td>0.424001</td>\n",
       "      <td>0.383256</td>\n",
       "      <td>0.509915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.548968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance of Admit</th>\n",
       "      <td>0.806873</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.699380</td>\n",
       "      <td>0.680378</td>\n",
       "      <td>0.655735</td>\n",
       "      <td>0.878284</td>\n",
       "      <td>0.548968</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GRE Score  TOEFL Score  University Rating       SOP  \\\n",
       "GRE Score           1.000000     0.831137           0.650135  0.613269   \n",
       "TOEFL Score         0.831137     1.000000           0.669767  0.650534   \n",
       "University Rating   0.650135     0.669767           1.000000  0.730656   \n",
       "SOP                 0.613269     0.650534           0.730656  1.000000   \n",
       "LOR                 0.538649     0.552455           0.631142  0.692200   \n",
       "CGPA                0.829021     0.818476           0.723023  0.714796   \n",
       "Research            0.570726     0.476830           0.436357  0.424001   \n",
       "Chance of Admit     0.806873     0.791934           0.699380  0.680378   \n",
       "\n",
       "                       LOR       CGPA  Research  Chance of Admit   \n",
       "GRE Score          0.538649  0.829021  0.570726          0.806873  \n",
       "TOEFL Score        0.552455  0.818476  0.476830          0.791934  \n",
       "University Rating  0.631142  0.723023  0.436357          0.699380  \n",
       "SOP                0.692200  0.714796  0.424001          0.680378  \n",
       "LOR                1.000000  0.651118  0.383256          0.655735  \n",
       "CGPA               0.651118  1.000000  0.509915          0.878284  \n",
       "Research           0.383256  0.509915  1.000000          0.548968  \n",
       "Chance of Admit    0.655735  0.878284  0.548968          1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA',\n",
       "       'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:,:-1]\n",
    "y=dataset[\"Chance of Admit \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation\n",
    "u=np.mean(X_train,axis=0)\n",
    "std=np.std(X_train,axis=0)\n",
    "X_train=(X_train-u)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the data- Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=X_train.shape[0]  #no. of training examples\n",
    "n=X_train.shape[1]  #no. of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_train.values #obtaining a numpy array from the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.ones((m,1)) #generating bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X=np.hstack((x,X)) #appending bias to each training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(X,theta):\n",
    "    return np.dot(X,theta)\n",
    "\n",
    "def error(X,y,theta):\n",
    "    e = 0.0\n",
    "    y_ = hypothesis(X,theta)\n",
    "    e = np.sum((y-y_)**2)\n",
    "    \n",
    "    return e/m\n",
    "    \n",
    "def gradient(X,y,theta):\n",
    "    \n",
    "    y_ = hypothesis(X,theta)\n",
    "    grad = np.dot(X.T,(y_ - y))\n",
    "    m = X.shape[0]\n",
    "    return grad/m\n",
    "\n",
    "def gradient_descent(X,y,learning_rate = 0.01,max_iters=300):\n",
    "    \n",
    "    n = X.shape[1]\n",
    "    theta = np.zeros((n,))\n",
    "    error_list = []\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        e = error(X,y,theta)\n",
    "        error_list.append(e)\n",
    "        \n",
    "        #Gradient descent\n",
    "        grad = gradient(X,y,theta)\n",
    "        theta = theta - learning_rate*grad\n",
    "        \n",
    "    return theta,error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,error_list = gradient_descent(input_X,y,0.01,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5450344444444445,\n",
       " 0.5331477901670961,\n",
       " 0.5216020898808467,\n",
       " 0.5103808364543203,\n",
       " 0.49946875615828523,\n",
       " 0.4888516998971102,\n",
       " 0.47851654444376196,\n",
       " 0.4684511027496602,\n",
       " 0.45864404248710067,\n",
       " 0.4490848120603,\n",
       " 0.4397635733921767,\n",
       " 0.4306711408584268,\n",
       " 0.42179892579890227,\n",
       " 0.41313888608930344,\n",
       " 0.4046834803042794,\n",
       " 0.3964256260466282,\n",
       " 0.388358662056832,\n",
       " 0.38047631375303265,\n",
       " 0.3727726618840734,\n",
       " 0.3652421140077402,\n",
       " 0.3578793785330871,\n",
       " 0.35067944108999827,\n",
       " 0.3436375430111482,\n",
       " 0.33674916173148167,\n",
       " 0.3300099929284382,\n",
       " 0.3234159342425664,\n",
       " 0.3169630704330645,\n",
       " 0.31064765983628956,\n",
       " 0.30446612200752976,\n",
       " 0.29841502643744056,\n",
       " 0.2924910822446278,\n",
       " 0.28669112875499597,\n",
       " 0.28101212688677285,\n",
       " 0.27545115126763603,\n",
       " 0.2700053830171933,\n",
       " 0.26467210313424555,\n",
       " 0.2594486864338793,\n",
       " 0.25433259598451646,\n",
       " 0.24932137799967277,\n",
       " 0.24441265714335514,\n",
       " 0.2396041322118297,\n",
       " 0.23489357215793685,\n",
       " 0.23027881242725035,\n",
       " 0.22575775157821606,\n",
       " 0.22132834816097188,\n",
       " 0.21698861783188697,\n",
       " 0.212736630682969,\n",
       " 0.20857050876721084,\n",
       " 0.20448842380268578,\n",
       " 0.20048859503978225,\n",
       " 0.19656928727739817,\n",
       " 0.19272880901521816,\n",
       " 0.18896551073037327,\n",
       " 0.18527778326785374,\n",
       " 0.18166405633501556,\n",
       " 0.17812279709140189,\n",
       " 0.17465250882590083,\n",
       " 0.1712517297139823,\n",
       " 0.16791903164842045,\n",
       " 0.16465301913749816,\n",
       " 0.16145232826523842,\n",
       " 0.158315625708694,\n",
       " 0.15524160780777585,\n",
       " 0.15222899968350478,\n",
       " 0.14927655440093898,\n",
       " 0.14638305217336223,\n",
       " 0.1435472996046234,\n",
       " 0.14076812896678967,\n",
       " 0.13804439751052788,\n",
       " 0.1353749868058548,\n",
       " 0.13275880211110197,\n",
       " 0.13019477176812866,\n",
       " 0.12768184662198764,\n",
       " 0.12521899946339946,\n",
       " 0.12280522449253477,\n",
       " 0.12043953680272933,\n",
       " 0.11812097188287353,\n",
       " 0.11584858513732241,\n",
       " 0.11362145142226844,\n",
       " 0.11143866459760716,\n",
       " 0.10929933709340313,\n",
       " 0.10720259949013712,\n",
       " 0.10514760011198103,\n",
       " 0.10313350463240543,\n",
       " 0.10115949569148021,\n",
       " 0.09922477252427757,\n",
       " 0.09732855059983238,\n",
       " 0.0954700612701547,\n",
       " 0.09364855142882805,\n",
       " 0.09186328317876051,\n",
       " 0.09011353350868662,\n",
       " 0.08839859397804718,\n",
       " 0.08671777040989972,\n",
       " 0.08507038259153547,\n",
       " 0.08345576398250142,\n",
       " 0.08187326142974542,\n",
       " 0.0803222348896202,\n",
       " 0.07880205715649877,\n",
       " 0.0773121135977699,\n",
       " 0.0758518018949948,\n",
       " 0.07442053179102005,\n",
       " 0.07301772484285364,\n",
       " 0.07164281418012054,\n",
       " 0.0702952442689261,\n",
       " 0.0689744706809633,\n",
       " 0.06767995986770851,\n",
       " 0.06641118893955902,\n",
       " 0.06516764544977217,\n",
       " 0.06394882718307224,\n",
       " 0.06275424194879856,\n",
       " 0.06158340737847302,\n",
       " 0.060435850727670555,\n",
       " 0.05931110868208222,\n",
       " 0.05820872716766299,\n",
       " 0.05712826116476322,\n",
       " 0.05606927452614438,\n",
       " 0.055031339798785175,\n",
       " 0.05401403804938649,\n",
       " 0.053016958693487326,\n",
       " 0.052039699328107356,\n",
       " 0.05108186556783363,\n",
       " 0.05014307088427275,\n",
       " 0.04922293644879169,\n",
       " 0.04832109097847309,\n",
       " 0.04743717058521301,\n",
       " 0.04657081862789182,\n",
       " 0.045721685567550206,\n",
       " 0.04488942882550459,\n",
       " 0.04407371264433822,\n",
       " 0.04327420795170592,\n",
       " 0.042490592226891784,\n",
       " 0.04172254937006148,\n",
       " 0.04096976957415162,\n",
       " 0.04023194919934027,\n",
       " 0.03950879065004469,\n",
       " 0.038800002254393125,\n",
       " 0.03810529814611877,\n",
       " 0.03742439814882564,\n",
       " 0.03675702766257721,\n",
       " 0.03610291755275971,\n",
       " 0.03546180404117299,\n",
       " 0.034833428599303475,\n",
       " 0.03421753784373392,\n",
       " 0.03361388343364661,\n",
       " 0.033022221970377234,\n",
       " 0.032442314898977385,\n",
       " 0.03187392841174478,\n",
       " 0.031316833353681454,\n",
       " 0.03077080512984061,\n",
       " 0.030235623614523786,\n",
       " 0.029711073062291246,\n",
       " 0.029196942020748448,\n",
       " 0.028693023245073217,\n",
       " 0.02819911361424811,\n",
       " 0.027715014048963926,\n",
       " 0.02724052943116049,\n",
       " 0.026775468525171934,\n",
       " 0.026319643900444358,\n",
       " 0.02587287185579366,\n",
       " 0.025434972345173664,\n",
       " 0.025005768904923273,\n",
       " 0.02458508858246358,\n",
       " 0.024172761866415614,\n",
       " 0.02376862261811052,\n",
       " 0.02337250800446419,\n",
       " 0.022984258432188688,\n",
       " 0.022603717483314568,\n",
       " 0.022230731851997015,\n",
       " 0.02186515128258074,\n",
       " 0.021506828508898037,\n",
       " 0.021155619194775946,\n",
       " 0.020811381875727748,\n",
       " 0.02047397790180553,\n",
       " 0.020143271381590586,\n",
       " 0.01981912912729906,\n",
       " 0.019501420600980146,\n",
       " 0.019190017861785622,\n",
       " 0.018884795514289066,\n",
       " 0.01858563065783368,\n",
       " 0.018292402836888648,\n",
       " 0.01800499399239343,\n",
       " 0.017723288414070778,\n",
       " 0.017447172693688617,\n",
       " 0.017176535679252605,\n",
       " 0.016911268430110038,\n",
       " 0.016651264172947593,\n",
       " 0.01639641825866476,\n",
       " 0.016146628120105547,\n",
       " 0.01590179323063143,\n",
       " 0.015661815063519033,\n",
       " 0.015426597052165368,\n",
       " 0.015196044551085563,\n",
       " 0.014970064797686427,\n",
       " 0.01474856687480099,\n",
       " 0.014531461673968463,\n",
       " 0.014318661859445074,\n",
       " 0.014110081832931094,\n",
       " 0.013905637698999766,\n",
       " 0.013705247231214109,\n",
       " 0.013508829838918336,\n",
       " 0.013316306534689773,\n",
       " 0.013127599902438572,\n",
       " 0.012942634066142385,\n",
       " 0.012761334659202993,\n",
       " 0.012583628794412896,\n",
       " 0.012409445034519436,\n",
       " 0.012238713363374799,\n",
       " 0.01207136515765991,\n",
       " 0.01190733315917124,\n",
       " 0.011746551447658933,\n",
       " 0.011588955414205453,\n",
       " 0.011434481735133985,\n",
       " 0.011283068346436128,\n",
       " 0.011134654418708166,\n",
       " 0.010989180332586435,\n",
       " 0.010846587654671265,\n",
       " 0.01070681911393007,\n",
       " 0.010569818578570032,\n",
       " 0.010435531033370861,\n",
       " 0.01030390255746881,\n",
       " 0.010174880302582486,\n",
       " 0.010048412471672269,\n",
       " 0.009924448298023997,\n",
       " 0.00980293802474921,\n",
       " 0.009683832884693074,\n",
       " 0.00956708508074222,\n",
       " 0.009452647766524304,\n",
       " 0.009340475027491841,\n",
       " 0.009230521862382211,\n",
       " 0.009122744165046649,\n",
       " 0.00901709870664086,\n",
       " 0.008913543118169994,\n",
       " 0.008812035873380903,\n",
       " 0.00871253627199483,\n",
       " 0.00861500442327377,\n",
       " 0.008519401229913773,\n",
       " 0.008425688372258777,\n",
       " 0.00833382829282861,\n",
       " 0.008243784181154698,\n",
       " 0.008155519958917699,\n",
       " 0.008069000265380726,\n",
       " 0.007984190443112507,\n",
       " 0.007901056523994567,\n",
       " 0.007819565215506924,\n",
       " 0.007739683887286534,\n",
       " 0.007661380557953349,\n",
       " 0.007584623882198409,\n",
       " 0.007509383138128836,\n",
       " 0.007435628214864775,\n",
       " 0.007363329600382956,\n",
       " 0.007292458369602254,\n",
       " 0.007222986172706306,\n",
       " 0.0071548852236983885,\n",
       " 0.007088128289184238,\n",
       " 0.007022688677377789,\n",
       " 0.006958540227325892,\n",
       " 0.006895657298347359,\n",
       " 0.00683401475968216,\n",
       " 0.006773587980346482,\n",
       " 0.0067143528191898555,\n",
       " 0.006656285615149879,\n",
       " 0.0065993631777010375,\n",
       " 0.006543562777493494,\n",
       " 0.006488862137178115,\n",
       " 0.006435239422414072,\n",
       " 0.0063826732330554605,\n",
       " 0.006331142594513154,\n",
       " 0.006280626949288565,\n",
       " 0.006231106148675946,\n",
       " 0.006182560444629694,\n",
       " 0.0061349704817935296,\n",
       " 0.006088317289688212,\n",
       " 0.006042582275054809,\n",
       " 0.005997747214350233,\n",
       " 0.005953794246392028,\n",
       " 0.005910705865149729,\n",
       " 0.005868464912679397,\n",
       " 0.005827054572198879,\n",
       " 0.005786458361300865,\n",
       " 0.005746660125300898,\n",
       " 0.005707644030717793,\n",
       " 0.005669394558883762,\n",
       " 0.005631896499681727,\n",
       " 0.005595134945407132,\n",
       " 0.005559095284752022,\n",
       " 0.005523763196908706,\n",
       " 0.005489124645790781,\n",
       " 0.005455165874369169,\n",
       " 0.005421873399120831,\n",
       " 0.005389234004587877,\n",
       " 0.005357234738045042,\n",
       " 0.005325862904273159,\n",
       " 0.005295106060436685,\n",
       " 0.0052649520110630964,\n",
       " 0.005235388803122282,\n",
       " 0.00520640472120366,\n",
       " 0.00517798828278945,\n",
       " 0.005150128233621869,\n",
       " 0.005122813543162519,\n",
       " 0.005096033400142166,\n",
       " 0.005069777208199003,\n",
       " 0.005044034581603729,\n",
       " 0.005018795341069682,\n",
       " 0.004994049509646343,\n",
       " 0.004969787308694509,\n",
       " 0.004945999153941577,\n",
       " 0.004922675651615309,\n",
       " 0.004899807594654517,\n",
       " 0.004877385958995121,\n",
       " 0.004855401899930145,\n",
       " 0.004833846748542075,\n",
       " 0.004812712008206263,\n",
       " 0.0047919893511638514,\n",
       " 0.004771670615162921,\n",
       " 0.004751747800166397,\n",
       " 0.004732213065125554,\n",
       " 0.004713058724817641,\n",
       " 0.004694277246746432,\n",
       " 0.004675861248104488,\n",
       " 0.0046578034927958045,\n",
       " 0.004640096888517709,\n",
       " 0.004622734483900856,\n",
       " 0.004605709465706056,\n",
       " 0.004589015156076933,\n",
       " 0.004572645009847213,\n",
       " 0.004556592611901571,\n",
       " 0.004540851674589048,\n",
       " 0.004525416035187849,\n",
       " 0.004510279653420641,\n",
       " 0.004495436609019233,\n",
       " 0.0044808810993377645,\n",
       " 0.004466607437013333,\n",
       " 0.004452610047673199,\n",
       " 0.00443888346768755,\n",
       " 0.004425422341967068,\n",
       " 0.004412221421804205,\n",
       " 0.004399275562757492,\n",
       " 0.00438657972257789,\n",
       " 0.004374128959176438,\n",
       " 0.004361918428632256,\n",
       " 0.004349943383240302,\n",
       " 0.004338199169597836,\n",
       " 0.004326681226729054,\n",
       " 0.004315385084246956,\n",
       " 0.004304306360551861,\n",
       " 0.004293440761065692,\n",
       " 0.004282784076501404,\n",
       " 0.0042723321811668925,\n",
       " 0.00426208103130256,\n",
       " 0.004252026663452044,\n",
       " 0.004242165192865269,\n",
       " 0.0042324928119333366,\n",
       " 0.0042230057886545385,\n",
       " 0.0042137004651308565,\n",
       " 0.004204573256094398,\n",
       " 0.004195620647463148,\n",
       " 0.004186839194925439,\n",
       " 0.004178225522552588,\n",
       " 0.004169776321439141,\n",
       " 0.0041614883483701345,\n",
       " 0.0041533584245149495,\n",
       " 0.004145383434147033,\n",
       " 0.004137560323389185,\n",
       " 0.0041298860989837614,\n",
       " 0.004122357827087364,\n",
       " 0.004114972632089476,\n",
       " 0.0041077276954546325,\n",
       " 0.004100620254587599,\n",
       " 0.004093647601721162,\n",
       " 0.004086807082825961,\n",
       " 0.00408009609654213,\n",
       " 0.004073512093132084,\n",
       " 0.00406705257345418,\n",
       " 0.004060715087956811,\n",
       " 0.004054497235692489,\n",
       " 0.004048396663351524,\n",
       " 0.004042411064314964,\n",
       " 0.004036538177726349,\n",
       " 0.004030775787581941,\n",
       " 0.004025121721839032,\n",
       " 0.004019573851542009,\n",
       " 0.00401413008996581,\n",
       " 0.004008788391776393,\n",
       " 0.0040035467522079185,\n",
       " 0.003998403206256297,\n",
       " 0.00399335582788879,\n",
       " 0.003988402729269309,\n",
       " 0.003983542059999149,\n",
       " 0.003978772006372806,\n",
       " 0.00397409079064861,\n",
       " 0.003969496670333852,\n",
       " 0.003964987937484147,\n",
       " 0.003960562918016731,\n",
       " 0.003956219971037399,\n",
       " 0.00395195748818085,\n",
       " 0.003947773892964145,\n",
       " 0.003943667640153027,\n",
       " 0.0039396372151408445,\n",
       " 0.0039356811333398235,\n",
       " 0.00393179793958446,\n",
       " 0.0039279862075467685,\n",
       " 0.003924244539163162,\n",
       " 0.003920571564072727,\n",
       " 0.003916965939066694,\n",
       " 0.003913426347548825,\n",
       " 0.003909951499006557,\n",
       " 0.003906540128492652,\n",
       " 0.0039031909961171666,\n",
       " 0.003899902886549525,\n",
       " 0.0038966746085304723,\n",
       " 0.0038935049943937695,\n",
       " 0.003890392899597388,\n",
       " 0.0038873372022640105,\n",
       " 0.003884336802730693,\n",
       " 0.003881390623107482,\n",
       " 0.0038784976068447926,\n",
       " 0.0038756567183094058,\n",
       " 0.003872866942368897,\n",
       " 0.003870127283984324,\n",
       " 0.003867436767811022,\n",
       " 0.003864794437807324,\n",
       " 0.0038621993568510884,\n",
       " 0.0038596506063638195,\n",
       " 0.0038571472859423015,\n",
       " 0.003854688512997522,\n",
       " 0.0038522734224007917,\n",
       " 0.003849901166136916,\n",
       " 0.003847570912964234,\n",
       " 0.003845281848081446,\n",
       " 0.003843033172801049,\n",
       " 0.003840824104229265,\n",
       " 0.0038386538749523593,\n",
       " 0.0038365217327291554,\n",
       " 0.003834426940189713,\n",
       " 0.0038323687745399518,\n",
       " 0.0038303465272721735,\n",
       " 0.00382835950388135,\n",
       " 0.0038264070235870255,\n",
       " 0.003824488419060764,\n",
       " 0.0038226030361590163,\n",
       " 0.0038207502336613116,\n",
       " 0.003818929383013611,\n",
       " 0.0038171398680768224,\n",
       " 0.0038153810848802782,\n",
       " 0.0038136524413801168,\n",
       " 0.0038119533572224893,\n",
       " 0.0038102832635114486,\n",
       " 0.0038086416025814767,\n",
       " 0.003807027827774516,\n",
       " 0.0038054414032214446,\n",
       " 0.003803881803627903,\n",
       " 0.003802348514064351,\n",
       " 0.0038008410297603427,\n",
       " 0.0037993588559028417,\n",
       " 0.00379790150743859,\n",
       " 0.0037964685088803804,\n",
       " 0.003795059394117187,\n",
       " 0.003793673706228072,\n",
       " 0.003792310997299794,\n",
       " 0.00379097082824804,\n",
       " 0.0037896527686422086,\n",
       " 0.0037883563965336762,\n",
       " 0.0037870812982874888,\n",
       " 0.003785827068417389,\n",
       " 0.003784593309424117,\n",
       " 0.003783379631636946,\n",
       " 0.0037821856530583465,\n",
       " 0.0037810109992117594,\n",
       " 0.0037798553029923633,\n",
       " 0.0037787182045208533,\n",
       " 0.0037775993510000836,\n",
       " 0.0037764983965745866,\n",
       " 0.0037754150021928738,\n",
       " 0.003774348835472473,\n",
       " 0.0037732995705676625,\n",
       " 0.003772266888039806,\n",
       " 0.0037712504747302914,\n",
       " 0.003770250023635988,\n",
       " 0.0037692652337871706,\n",
       " 0.0037682958101278776,\n",
       " 0.00376734146339865,\n",
       " 0.0037664019100215923,\n",
       " 0.0037654768719877175,\n",
       " 0.0037645660767465414,\n",
       " 0.0037636692570978698,\n",
       " 0.003762786151085724,\n",
       " 0.0037619165018943825,\n",
       " 0.0037610600577464943,\n",
       " 0.0037602165718032044,\n",
       " 0.0037593858020662785,\n",
       " 0.0037585675112821555,\n",
       " 0.003757761466847928,\n",
       " 0.0037569674407191673,\n",
       " 0.0037561852093196024,\n",
       " 0.003755414553452581,\n",
       " 0.0037546552582142876,\n",
       " 0.0037539071129086923,\n",
       " 0.0037531699109641984,\n",
       " 0.0037524434498519173,\n",
       " 0.003751727531005608]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x228cf910f88>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>314</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>321</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>297</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>316</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>312</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>325</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>299</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "322        314          107                  2  2.5   4.0  8.27         0\n",
       "305        321          109                  3  3.5   3.5  8.80         1\n",
       "159        297          100                  1  1.5   2.0  7.90         0\n",
       "428        316          103                  2  2.0   4.5  8.74         0\n",
       "232        312          107                  2  2.5   3.5  8.27         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "215        330          116                  5  5.0   4.5  9.36         1\n",
       "64         325          111                  3  3.0   3.5  8.70         0\n",
       "347        299           94                  1  1.0   1.0  7.34         0\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "\n",
       "[270 rows x 7 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=np.mean(X_test,axis=0)\n",
    "std=np.std(X_test,axis=0)\n",
    "X_test=(X_test-u)/std\n",
    "x=np.ones((X_test.shape[0],1))\n",
    "X_test=np.hstack((x,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=hypothesis(X_test,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67735915, 0.77052904, 0.52656618, 0.71583632, 0.66202037,\n",
       "       0.95436825, 0.60439416, 0.5753309 , 0.53387249, 0.70779916,\n",
       "       0.83558586, 0.85886457, 0.54424186, 0.71987178, 0.71946325,\n",
       "       0.70153839, 0.74566892, 0.52419687, 0.59886384, 0.79795141,\n",
       "       0.9827474 , 0.61212991, 0.74620315, 0.63915422, 0.44898142,\n",
       "       0.66245728, 0.56115432, 0.79890185, 0.84747189, 0.68668321,\n",
       "       0.61826403, 0.65627882, 0.91909007, 0.60940894, 0.88935787,\n",
       "       0.95436825, 0.65228178, 0.63915422, 0.92491699, 0.96450878,\n",
       "       0.7603175 , 0.64699025, 0.66763158, 0.69274285, 0.79249522,\n",
       "       0.57718862, 0.62564595, 0.63139234, 0.66473045, 0.71954105,\n",
       "       0.53392538, 0.74969042, 0.90177053, 0.73711604, 0.71483033,\n",
       "       0.72778755, 0.74690212, 0.51492875, 0.6237802 , 0.70244231,\n",
       "       0.72180284, 0.68179416, 0.44898142, 0.51455083, 0.91086168,\n",
       "       0.69527825, 0.62370963, 0.53387249, 0.73327361, 0.84652291,\n",
       "       0.79779639, 0.96122228, 0.62456757, 0.52390376, 0.7870852 ,\n",
       "       0.93297451, 0.69182302, 0.76811716, 0.71219732, 0.87037989,\n",
       "       0.6654509 , 0.64343103, 0.95297105, 0.93713698, 0.76855298,\n",
       "       0.57086128, 0.68893149, 0.65228178, 0.71409213, 0.4392778 ,\n",
       "       0.94485887, 0.65910042, 0.64908129, 0.68668321, 0.61600183,\n",
       "       0.72020244, 0.61871167, 0.60137281, 0.65435536, 0.88879804,\n",
       "       0.79680295, 0.61091147, 0.73948953, 0.6630437 , 0.65227958,\n",
       "       0.57826609, 0.85606806, 0.73869779, 0.77245207, 0.62773389,\n",
       "       0.72945744, 0.74566892, 0.68241879, 0.73808222, 0.78227839,\n",
       "       0.73925873, 0.72880568, 0.7117619 , 0.66819551, 0.65703147,\n",
       "       0.56174046, 0.74620315, 0.65685474, 0.74865383, 0.8578726 ,\n",
       "       0.74533214, 0.69384522, 0.84730196, 0.64738883, 0.90630962,\n",
       "       0.93363454, 0.59131057, 0.67483165, 0.66834303, 0.6758403 ,\n",
       "       0.62786222, 0.93167929, 0.60586502, 0.78227786, 0.65589672,\n",
       "       0.84184535, 0.79890185, 0.66622666, 0.74533214, 0.84677724,\n",
       "       0.9024721 , 0.99035555, 0.7764691 , 0.64687773, 0.73907706,\n",
       "       0.73585354, 0.63581188, 0.67525418, 0.65604179, 0.59598969,\n",
       "       0.86090804, 0.75241249, 0.52339337, 0.84538006, 0.51003793,\n",
       "       0.61995206, 0.72371893, 0.89284638, 0.90307411, 0.61967822,\n",
       "       0.78470549, 0.80719913, 0.62982838, 0.66373248, 0.56174046,\n",
       "       0.65589672, 0.81107065, 0.8616996 , 0.76555035, 0.78402751,\n",
       "       0.80529289, 0.73327361, 0.85922897, 0.77644249, 0.69420814,\n",
       "       0.62193532, 0.9508711 , 0.71079131, 0.48139402, 0.80726144,\n",
       "       0.84782341, 0.60581382, 0.75708263, 0.64505162, 0.78812788,\n",
       "       0.52960369, 0.97078976, 0.52272641, 0.77726359, 0.67587741,\n",
       "       0.59539615, 0.80259673, 0.85886457, 0.85405621, 0.7968745 ,\n",
       "       0.89395356, 0.68893149, 0.79399917, 0.59753766, 0.51259786,\n",
       "       0.80529289, 0.67525418, 0.67126368, 0.57028657, 0.81069472,\n",
       "       0.77212623, 0.73455815, 0.80259673, 0.6605961 , 0.5753309 ,\n",
       "       0.98128222, 0.70314076, 0.85506637, 0.70121923, 0.4392778 ,\n",
       "       0.8840422 , 0.77067211, 0.74112036, 0.46889956, 0.90621568,\n",
       "       0.75941595, 0.66834303, 0.8840422 , 0.89425097, 0.74606085,\n",
       "       0.63301406, 0.80250178, 0.70459083, 0.58692292, 0.70359031,\n",
       "       0.65227958, 0.51492875, 0.70359031, 0.54819972, 0.79795141,\n",
       "       0.51216002, 0.6579362 , 0.65542362, 0.7870852 , 0.53881196,\n",
       "       0.64687773, 0.89260897, 0.6654509 , 0.88400928, 0.62684552,\n",
       "       0.94019422, 0.83478191, 0.46618651, 0.68241879, 0.6303626 ,\n",
       "       0.66530704, 0.9674508 , 0.67442768, 0.83558531, 0.932018  ,\n",
       "       0.85864598, 0.59539615, 0.95297105, 0.65013526, 0.54795443,\n",
       "       0.90833691, 0.7532144 , 0.43949497, 0.94485887, 0.80105951])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.52399859232963\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test,preds)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
